{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os, random\n",
    "import math\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from numpy import var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA\n",
    "THRESHOLD = [0.3, 0.35 ,0.4, 0.45, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "DATASET = \"GoogleDataset\\GDatasetSplit\"\n",
    "\n",
    "models = [\n",
    "  \"VGG-Face\",\n",
    "  \"Facenet\",\n",
    "  \"Facenet512\",\n",
    "  \"OpenFace\",\n",
    "  \"DeepFace\",\n",
    "  \"DeepID\",\n",
    "  \"ArcFace\",\n",
    "  \"Dlib\",\n",
    "  \"SFace\",\n",
    "  \"GhostFaceNet\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that generates embeddings for a given image\n",
    "def Represent(path, model = 0):\n",
    "    embedding_objs = DeepFace.represent(\n",
    "    img_path = path,\n",
    "    model_name= models[model],\n",
    "    enforce_detection=False,\n",
    "    )\n",
    "    SUT_embeddings = embedding_objs[0]['embedding']\n",
    "    return torch.FloatTensor(SUT_embeddings)\n",
    "\n",
    "#Utility function that counts the number of files in a directory\n",
    "\n",
    "def count_files_in_directory(directory):\n",
    "    # Create a Path object\n",
    "    path = Path(directory)\n",
    "    # Count only files (ignoring subdirectories)\n",
    "    return sum(1 for f in path.iterdir() if f.is_file())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompareRefSet(identityPath, samplePath, threshold):\n",
    "    referenceSet = os.path.join(identityPath, \"real\")\n",
    "    underTest= Represent(samplePath)\n",
    "    \n",
    "    currentSimilarity = 0\n",
    "    for file in os.listdir(referenceSet):\n",
    "        refSample = os.path.join(referenceSet, file)\n",
    "        if(refSample == samplePath):\n",
    "            continue\n",
    "\n",
    "        refEmbedding = Represent(refSample)   \n",
    "\n",
    "        similarity = torch.nn.functional.cosine_similarity(underTest, refEmbedding, dim=0)\n",
    "        if(similarity > currentSimilarity):\n",
    "            currentSimilarity = similarity  \n",
    "\n",
    "    if(currentSimilarity > threshold):\n",
    "        return (True, currentSimilarity)\n",
    "    else:\n",
    "        return (False, currentSimilarity)\n",
    "    \n",
    "\n",
    "            \n",
    "\n",
    "def ProcessDatasetFakes(threshold, showTqdm = True):\n",
    "    Result = []\n",
    "    Acc = []\n",
    "    if(showTqdm):\n",
    "        list = tqdm(os.listdir(DATASET), desc=\"Processing Fakes\")\n",
    "    else:\n",
    "        list = os.listdir(DATASET)\n",
    "    for file in list:\n",
    "        identity = os.path.join(DATASET, file)\n",
    "        expectedResult = False\n",
    "\n",
    "        fakeFolder = os.path.join(identity, \"fake\")\n",
    "        underTest = os.path.join(fakeFolder,random.choice(os.listdir(fakeFolder)))\n",
    "\n",
    "        result = CompareRefSet(identity, underTest, threshold)\n",
    "\n",
    "        if(result[0] == expectedResult):\n",
    "            Result.append(1)\n",
    "        else:\n",
    "            Result.append(0)\n",
    "\n",
    "        Acc.append(result[1])\n",
    "\n",
    "    return (Result, Acc)\n",
    "            \n",
    "\n",
    "def ProcessDatasetReal(threshold, showTqdm = True):\n",
    "    Result = []\n",
    "    Acc = []\n",
    "    if(showTqdm):\n",
    "        list = tqdm(os.listdir(DATASET), desc=\"Processing Reals\")\n",
    "    else:\n",
    "        list = os.listdir(DATASET)\n",
    "\n",
    "    for file in list:\n",
    "        identity = os.path.join(DATASET, file)\n",
    "        expectedResult = True\n",
    "\n",
    "        realFolder = os.path.join(identity, \"real\")\n",
    "\n",
    "        if(count_files_in_directory(realFolder) > 1):\n",
    "            underTest = os.path.join(realFolder, random.choice(os.listdir(realFolder)))\n",
    "            result = CompareRefSet(identity, underTest, threshold) \n",
    "            if(result[0] == expectedResult):\n",
    "                Result.append(1)\n",
    "            else:\n",
    "                Result.append(0)\n",
    "            \n",
    "            Acc.append(result[1])\n",
    "\n",
    "\n",
    "    return (Result, Acc)\n",
    "\n",
    "\n",
    "def PrintResults(fakeResult, RealResult, t):     \n",
    "\n",
    "    print(f\"Test using {t} as threshold is finished\")\n",
    "\n",
    "    print(f\"Accuracy: {sum(fakeResult[0])/len(fakeResult[0])} in detecting fakes over {len(fakeResult[0])} identities. The average similarity was {sum(fakeResult[1])/len(fakeResult[1])} with a variance of {var(fakeResult[1])}\")\n",
    "    \n",
    "    print(f\"Accuracy: {sum(RealResult[0])/len(RealResult[0])} in detecting reals over {len(RealResult[0])} identities. The average similarity was {sum(RealResult[1])/len(RealResult[1])} with a variance of {var(RealResult[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test using 0.3 as threshold is finished\n",
      "Accuracy: 0.7395833333333334 in detecting fakes over 96 identities. The average similarity was 0.22935403883457184 with a variance of 0.016292855143547058\n",
      "Accuracy: 0.7241379310344828 in detecting reals over 29 identities. The average similarity was 0.5059651136398315 with a variance of 0.05290611833333969\n",
      "Test using 0.35 as threshold is finished\n",
      "Accuracy: 0.8333333333333334 in detecting fakes over 96 identities. The average similarity was 0.23059342801570892 with a variance of 0.016379594802856445\n",
      "Accuracy: 0.7241379310344828 in detecting reals over 29 identities. The average similarity was 0.5140664577484131 with a variance of 0.04630586504936218\n",
      "Test using 0.4 as threshold is finished\n",
      "Accuracy: 0.8645833333333334 in detecting fakes over 96 identities. The average similarity was 0.2278105467557907 with a variance of 0.01652688719332218\n",
      "Accuracy: 0.6206896551724138 in detecting reals over 29 identities. The average similarity was 0.46927517652511597 with a variance of 0.045224063098430634\n",
      "Test using 0.45 as threshold is finished\n",
      "Accuracy: 0.90625 in detecting fakes over 96 identities. The average similarity was 0.2278105467557907 with a variance of 0.01652688719332218\n",
      "Accuracy: 0.6551724137931034 in detecting reals over 29 identities. The average similarity was 0.4885194003582001 with a variance of 0.046222854405641556\n",
      "Test using 0.5 as threshold is finished\n",
      "Accuracy: 0.9791666666666666 in detecting fakes over 96 identities. The average similarity was 0.2301407903432846 with a variance of 0.016348108649253845\n",
      "Accuracy: 0.6206896551724138 in detecting reals over 29 identities. The average similarity was 0.49391990900039673 with a variance of 0.046955887228250504\n",
      "Test using 0.6 as threshold is finished\n",
      "Accuracy: 0.9895833333333334 in detecting fakes over 96 identities. The average similarity was 0.23059342801570892 with a variance of 0.016379594802856445\n",
      "Accuracy: 0.3448275862068966 in detecting reals over 29 identities. The average similarity was 0.4960862100124359 with a variance of 0.045845162123441696\n",
      "Test using 0.7 as threshold is finished\n",
      "Accuracy: 1.0 in detecting fakes over 96 identities. The average similarity was 0.23059342801570892 with a variance of 0.016379594802856445\n",
      "Accuracy: 0.2413793103448276 in detecting reals over 29 identities. The average similarity was 0.49758216738700867 with a variance of 0.045838385820388794\n",
      "Test using 0.8 as threshold is finished\n",
      "Accuracy: 1.0 in detecting fakes over 96 identities. The average similarity was 0.22935403883457184 with a variance of 0.016292855143547058\n",
      "Accuracy: 0.0 in detecting reals over 29 identities. The average similarity was 0.4946545958518982 with a variance of 0.04501999914646149\n"
     ]
    }
   ],
   "source": [
    "for t in THRESHOLD:\n",
    "    PrintResults(ProcessDatasetFakes(t, False), ProcessDatasetReal(t, False), t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
