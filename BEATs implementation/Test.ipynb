{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Py Torch Model load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torchaudio\n",
    "import gc\n",
    "import os\n",
    "from BEATs import BEATs, BEATsConfig\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "THRESHOLD = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AIFF': 'AIFF (Apple/SGI)',\n",
       " 'AU': 'AU (Sun/NeXT)',\n",
       " 'AVR': 'AVR (Audio Visual Research)',\n",
       " 'CAF': 'CAF (Apple Core Audio File)',\n",
       " 'FLAC': 'FLAC (Free Lossless Audio Codec)',\n",
       " 'HTK': 'HTK (HMM Tool Kit)',\n",
       " 'SVX': 'IFF (Amiga IFF/SVX8/SV16)',\n",
       " 'MAT4': 'MAT4 (GNU Octave 2.0 / Matlab 4.2)',\n",
       " 'MAT5': 'MAT5 (GNU Octave 2.1 / Matlab 5.0)',\n",
       " 'MPC2K': 'MPC (Akai MPC 2k)',\n",
       " 'OGG': 'OGG (OGG Container format)',\n",
       " 'PAF': 'PAF (Ensoniq PARIS)',\n",
       " 'PVF': 'PVF (Portable Voice Format)',\n",
       " 'RAW': 'RAW (header-less)',\n",
       " 'RF64': 'RF64 (RIFF 64)',\n",
       " 'SD2': 'SD2 (Sound Designer II)',\n",
       " 'SDS': 'SDS (Midi Sample Dump Standard)',\n",
       " 'IRCAM': 'SF (Berkeley/IRCAM/CARL)',\n",
       " 'VOC': 'VOC (Creative Labs)',\n",
       " 'W64': 'W64 (SoundFoundry WAVE 64)',\n",
       " 'WAV': 'WAV (Microsoft)',\n",
       " 'NIST': 'WAV (NIST Sphere)',\n",
       " 'WAVEX': 'WAVEX (Microsoft)',\n",
       " 'WVE': 'WVE (Psion Series 3)',\n",
       " 'XI': 'XI (FastTracker 2)'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "sf.available_formats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 2070 SUPER is available.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('BEATs_iter3_plus_AS2M.pt')\n",
    "\n",
    "cfg = BEATsConfig(checkpoint['cfg'])\n",
    "BEATs_model = BEATs(cfg)\n",
    "BEATs_model.load_state_dict(checkpoint['model'])\n",
    "BEATs_model = BEATs_model.to(device=\"cuda\")\n",
    "#BEATs_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torchaudio.load(uri=AUDIO, format=\"wav\")\n",
    "_x = x[0].to(device=\"cuda\")\n",
    "rep_x = BEATs_model.extract_features(_x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_name=os.path.join(REF_SET,\"maCheSuccede.wav\")\n",
    "sample = torchaudio.load(uri= audio_name,format=\"wav\")[0]\n",
    "sample = sample.to(device=\"cuda\")\n",
    "audio_rep = BEATs_model.extract_features(sample)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 264, 768])\n",
      "torch.Size([2, 760, 768])\n",
      "torch.Size([2, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5416378378868103"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(audio_rep.shape)\n",
    "print(rep_x.shape)\n",
    "ComputeSimilarity(audio_rep, rep_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_padding(tensor, target_shape):\n",
    "    padding = []\n",
    "    for dim, target_dim in zip(tensor.shape[::-1], target_shape[::-1]):\n",
    "        pad = target_dim - dim\n",
    "        padding.extend((0, pad))\n",
    "    return padding\n",
    "\n",
    "def ComputeSimilarity(t1, t2):\n",
    "    target_shape = (\n",
    "    max(t1.shape[0], t2.shape[0]),\n",
    "    max(t1.shape[1], t2.shape[1]),\n",
    "    max(t1.shape[2], t2.shape[2]),\n",
    "    )\n",
    "    \n",
    "\n",
    "    padding1 = calculate_padding(t1, target_shape)\n",
    "    padding2 = calculate_padding(t2, target_shape)\n",
    "\n",
    "    # Apply padding\n",
    "    padded_tensor1 = torch.nn.functional.pad(t1, padding1)\n",
    "    padded_tensor2 = torch.nn.functional.pad(t2, padding2)\n",
    "        \n",
    "    _sim = torch.nn.functional.cosine_similarity(padded_tensor1, padded_tensor2)\n",
    "    print(_sim.shape)\n",
    "    mean = _sim.max().item()\n",
    "    return(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "REF_SET = \"Audio/AlessandroReal/\"\n",
    "AUDIO = \"Audio/fake.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TESTS**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing refrence set files:  50%|█████     | 1/2 [00:00<00:00,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing refrence set files: 100%|██████████| 2/2 [00:00<00:00,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "x = torchaudio.load(uri=AUDIO, format=\"wav\")[0]\n",
    "x = x.to(device=\"cuda\")\n",
    "rep_x = BEATs_model.extract_features(x)[0]\n",
    "\n",
    "SIM = []\n",
    "\n",
    "for file in tqdm(os.listdir(REF_SET), desc=\"Processing refrence set files\"):\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    if(file.endswith(\".wav\")):\n",
    "\n",
    "        audio_name = os.path.join(REF_SET, file)\n",
    "        sample = torchaudio.load(uri= audio_name,format=os.path.splitext(file)[1])[0]\n",
    "        sample = sample.to(device=\"cuda\")\n",
    "        audio_rep = BEATs_model.extract_features(sample)[0]\n",
    "\n",
    "        sample = None\n",
    "        \n",
    "        SIM.append(ComputeSimilarity(rep_x, audio_rep))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6548163890838623\n",
      "fake\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Find the maximum similarity value\n",
    "max_similarity = max(SIM)\n",
    "\n",
    "print(max_similarity)\n",
    "\n",
    "if(max_similarity < THRESHOLD):\n",
    "    print(\"fake\")\n",
    "else:\n",
    "    print(\"real\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
